{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Librerías y drivers**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import teradatasql\n",
    "import openpyxl\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, date\n",
    "from datetime import timedelta\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Credenciales y conexión a Teradata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de conexión\n",
    "host = 'tdimpprd.entel.cl'\n",
    "user = 'P_CFAUNDEZ'\n",
    "password = 'Carlos_Entel_5052'\n",
    "database = 'CALIDAD'\n",
    "\n",
    " \n",
    "# Conectar a la base de datos\n",
    "conn = teradatasql.connect(\n",
    "    host=host,\n",
    "    user=user,\n",
    "    password=password,\n",
    "    database=database\n",
    ")\n",
    " \n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 1. Consultar la tabla `bitacora` para obtener las fechas de entrada y salida de las máquinas ---\n",
    "query_bitacora = \"\"\"\n",
    "SELECT \n",
    "    YEAR_ID,\n",
    "    MONTH_ID,\n",
    "    POP,\n",
    "    EVENTO\n",
    "FROM BITACORA_POP_CFS\n",
    "WHERE evento IN ('ENTRADA', 'SALIDA')\n",
    "\"\"\"\n",
    "bitacora_df = pd.read_sql(query_bitacora, conn)\n",
    "\n",
    "# --- 3. Preparar los datos para la consulta de KPIs ---\n",
    "\n",
    "def calcular_meses_adyacentes(year, month, evento):\n",
    "    \"\"\"Calcula el mes anterior y siguiente para un registro de entrada/salida.\"\"\"\n",
    "    dt = date(year, month, 1)\n",
    "    \n",
    "    if evento == 'ENTRADA':\n",
    "        mes_anterior = (dt - pd.DateOffset(months=1)).strftime('%Y%m')\n",
    "        mes_siguiente = dt.strftime('%Y%m')\n",
    "    elif evento == 'SALIDA':\n",
    "        mes_anterior = dt.strftime('%Y%m')\n",
    "        mes_siguiente = (dt + pd.DateOffset(months=1)).strftime('%Y%m')\n",
    "    else:\n",
    "        return None, None #Manejo de error, si el evento no es entrada o salida.\n",
    "        \n",
    "    return mes_anterior, mes_siguiente\n",
    "\n",
    "bitacora_df[['MES_ANTERIOR', 'MES_SIGUIENTE']] = bitacora_df.apply(lambda row: calcular_meses_adyacentes(row['YEAR_ID'], row['MONTH_ID'], row['EVENTO']), axis=1, result_type='expand')\n",
    "bitacora_df = bitacora_df.dropna(subset=['MES_ANTERIOR', 'MES_SIGUIENTE'])\n",
    "bitacora_df['MES_ANTERIOR'] = bitacora_df['MES_ANTERIOR'].astype(int)\n",
    "bitacora_df['MES_SIGUIENTE'] = bitacora_df['MES_SIGUIENTE'].astype(int)\n",
    "\n",
    "# --- 4. Consulta para obtener los KPIs ---\n",
    "\n",
    "# Crear una lista para almacenar los resultados de cada máquina\n",
    "resultados_kpis = []\n",
    "for index, row in bitacora_df.iterrows():\n",
    "    anio = row['YEAR_ID']\n",
    "    mes = row['MONTH_ID']\n",
    "    pop = row['POP']\n",
    "    mes_anterior = row['MES_ANTERIOR']\n",
    "    mes_siguiente = row['MES_SIGUIENTE']\n",
    "\n",
    "    print(mes_anterior)\n",
    "    print(mes_siguiente)\n",
    "\n",
    "    # Convertir 'YYYYMM' a 'YYYY-MM-01'\n",
    "    def convertir_fecha(mes):\n",
    "        mes = str(mes)  # Convertir el valor a cadena de texto\n",
    "        año = mes[:4]  # Los primeros 4 caracteres son el año\n",
    "        mes_numero = mes[4:]  # Los últimos 2 caracteres son el mes\n",
    "        return f\"{año}-{mes_numero}-01\"  # Crear la fecha en formato 'YYYY-MM-DD'\n",
    "\n",
    "    # Convertir las fechas\n",
    "    mes_anterior = convertir_fecha(mes_anterior)\n",
    "    mes_siguiente = convertir_fecha(mes_siguiente)\n",
    "\n",
    "    # Verificar las fechas convertidas\n",
    "    print(f\"Fecha anterior: {mes_anterior}\")\n",
    "    print(f\"Fecha siguiente: {mes_siguiente}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracción de KPI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P_CFAUNDEZ\\AppData\\Local\\Temp\\ipykernel_230192\\2714323255.py:71: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_kpis = pd.read_sql(query_kpis, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo Excel para PowerBI generado: datos_powerbi.xlsx\n"
     ]
    }
   ],
   "source": [
    "query_kpis = f\"\"\"\n",
    "SELECT \n",
    "    anio,\n",
    "    mes,\n",
    "    nombre_poligono,\n",
    "    -- Calculando el promedio de la \"velocidad de bajada\" por mes\n",
    "    AVG((aa.pxq_vdl / aa.qQOS_DownloadThroughput) / 1000) AS promedio_velocidad_bajada,\n",
    "    SUM(aa.qQOS_DownloadThroughput) as muestras_bajada,\n",
    "    AVG((aa.pxq_vul / aa.qQOS_UploadThroughput) / 1000) AS promedio_velocidad_subida,\n",
    "    SUM(aa.qQOS_UploadThroughput) as muestras_subida,\n",
    "    AVG(aa.pxq_latt / aa.qQOS_LatencyAverage) AS promedio_latencia,\n",
    "    SUM(aa.qQOS_LatencyAverage) as muestras_latencia,\n",
    "    aa.Device_SIMServiceProviderBrandName as Operador\n",
    "FROM (\n",
    "    SELECT\n",
    "        YEAR(A.FECHA) AS anio,\n",
    "        MONTH(A.FECHA) AS mes,\n",
    "        B.nombre_poligono AS nombre_poligono,\n",
    "        A.Device_SIMServiceProviderBrandName,\n",
    "        A.Connection_ServiceProviderBrandName,\n",
    "        A.Connection_Category,\n",
    "        A.Connection_Type,\n",
    "        A.Connection_GenerationCategory,\n",
    "        A.QOS_DownloadThroughputTestSize,\n",
    "        A.QOS_UploadThroughputTestSize,\n",
    "        SUM(CASE WHEN A.QOS_DOWNLOADTHROUGHPUTTESTSTATUS = 'COMPLETED' THEN 1 ELSE 0 END) AS qQOS_DownloadThroughput,\n",
    "        AVG(CASE WHEN A.QOS_DOWNLOADTHROUGHPUTTESTSTATUS = 'COMPLETED' THEN A.QOS_DOWNLOADTHROUGHPUT END) AS avgQOS_DownloadThroughput,\n",
    "        SUM(CASE WHEN A.QOS_UPLOADTHROUGHPUTTESTSTATUS = 'COMPLETED' THEN 1 ELSE 0 END) AS qQOS_UploadThroughput,\n",
    "        AVG(CASE WHEN A.QOS_UPLOADTHROUGHPUTTESTSTATUS = 'COMPLETED' THEN A.QOS_UPLOADTHROUGHPUT END) AS avgQOS_UploadThroughput,\n",
    "        SUM(CASE WHEN (A.QOS_DOWNLOADTHROUGHPUTTESTSTATUS = 'COMPLETED' OR A.QOS_UPLOADTHROUGHPUTTESTSTATUS = 'COMPLETED') THEN 1 ELSE 0 END) AS qQOS_LatencyAverage,\n",
    "        AVG(CASE WHEN (A.QOS_DOWNLOADTHROUGHPUTTESTSTATUS = 'COMPLETED' OR A.QOS_UPLOADTHROUGHPUTTESTSTATUS = 'COMPLETED') THEN A.QOS_LATENCYAVERAGE END) AS avgQOS_LatencyAverage,\n",
    "        SUM(CASE WHEN A.QOS_DOWNLOADTHROUGHPUTTESTSTATUS = 'COMPLETED' THEN 1 ELSE 0 END) * AVG(CASE WHEN A.QOS_DOWNLOADTHROUGHPUTTESTSTATUS = 'COMPLETED' THEN A.QOS_DOWNLOADTHROUGHPUT END) AS pxq_vdl,\n",
    "        SUM(CASE WHEN A.QOS_UPLOADTHROUGHPUTTESTSTATUS = 'COMPLETED' THEN 1 ELSE 0 END) * AVG(CASE WHEN A.QOS_UPLOADTHROUGHPUTTESTSTATUS = 'COMPLETED' THEN A.QOS_UPLOADTHROUGHPUT END) AS pxq_vul,\n",
    "        SUM(CASE WHEN (A.QOS_DOWNLOADTHROUGHPUTTESTSTATUS = 'COMPLETED' OR A.QOS_UPLOADTHROUGHPUTTESTSTATUS = 'COMPLETED') THEN 1 ELSE 0 END) * AVG(CASE WHEN (A.QOS_DOWNLOADTHROUGHPUTTESTSTATUS = 'COMPLETED' OR A.QOS_UPLOADTHROUGHPUTTESTSTATUS = 'COMPLETED') THEN A.QOS_LATENCYAVERAGE END) AS pxq_latt\n",
    "    FROM calidad.TUTELA_ONX_MOBILE_V A\n",
    "    JOIN calidad.BASE_POLIGONOS_GH7 B \n",
    "        ON A.LOCATION_GEOHASH7 = B.GEOHASH\n",
    "        AND A.FECHA BETWEEN DATE '2024-08-01' AND DATE '2024-10-01'\n",
    "        AND (A.QOS_DOWNLOADTHROUGHPUTTESTSTATUS = 'COMPLETED' \n",
    "        OR A.QOS_UPLOADTHROUGHPUTTESTSTATUS = 'COMPLETED')\n",
    "        AND A.Device_SIMServiceProviderBrandName IN ('Entel','Movistar','Claro','Wom')\n",
    "    WHERE A.Connection_Type <> 'WIFI'\n",
    "        AND A.Connection_Type <> 'CALL_SERVICE_ONLY'\n",
    "        AND A.Connection_Type <> 'CALL_SERVICE_ONLY_ROAMING'\n",
    "        AND A.Connection_Type <> 'NO_SERVICE'\n",
    "        AND (A.QOS_DownloadThroughputTestStatus = 'COMPLETED' \n",
    "        OR A.QOS_UploadThroughputTestStatus = 'COMPLETED')\n",
    "        AND B.tipo IN ('OPERATIVO', 'OPERATIVO_PARCIAL', 'INITIAL_TUNNING', \n",
    "                       'OPERATIVO_CON_INTERFERENCIA', 'PREVIO', 'EN_INTERVENCION',\n",
    "                       'ELIMINADO', 'HALTED', 'OPERATIVO_EVENTO', \n",
    "                       'INITIAL_TUNNING_PARCIAL', 'HALTED_FALLA')\n",
    "    GROUP BY \n",
    "        YEAR(A.FECHA),\n",
    "        MONTH(A.FECHA),\n",
    "        B.nombre_poligono,\n",
    "        A.Device_SIMServiceProviderBrandName,\n",
    "        A.Connection_ServiceProviderBrandName,\n",
    "        A.Connection_Category,\n",
    "        A.Connection_Type,\n",
    "        A.Connection_GenerationCategory,\n",
    "        A.QOS_DownloadThroughputTestSize,\n",
    "        A.QOS_UploadThroughputTestSize\n",
    ") AS aa\n",
    "GROUP BY \n",
    "    anio,\n",
    "    mes,\n",
    "    nombre_poligono,\n",
    "\tOperador;\n",
    "\"\"\"\n",
    "    \n",
    "df_kpis = pd.read_sql(query_kpis, conn)\n",
    "\n",
    "\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generar excel para Power Bi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar Excel para PowerBI\n",
    "def generar_excel_powerbi(df):\n",
    "    # Crear un DataFrame limpio para PowerBI        \n",
    "    df_powerbi = df.copy()\n",
    "\n",
    "    # Renombrar columnas para evitar confuciones\n",
    "    df_powerbi.rename(columns={\n",
    "        'ANIO': 'ANIO',\n",
    "        'MES': 'MES',\n",
    "        'promedio_velocidad_subida': 'Velocidad Descarga (mbps)',\n",
    "        'muestras_bajada': 'muestras_bajada',\n",
    "        'promedio_velocidad_bajada': 'Velocidad Subida (mbps)',\n",
    "        'muestras_subida': 'muestras_subida',\n",
    "        'promedio_latencia': 'Latencia (ms)',\n",
    "        'muestras_latencia': 'muestras_latencia',\n",
    "        'Operador':'Operador'\n",
    "\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Guardar el DataFrame en un archivo Excel\n",
    "    nombre_archivo_excel = f\"datos_powerbi.xlsx\"\n",
    "    with pd.ExcelWriter(nombre_archivo_excel, engine='xlsxwriter') as writer:\n",
    "        df_powerbi.to_excel(writer, index=False, sheet_name='Datos')\n",
    "\n",
    "        # Formatear la tabla para PowerBI\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets['Datos']\n",
    "        (max_row, max_col) = df_powerbi.shape\n",
    "        column_settings = [{'header': column} for column in df_powerbi.columns]\n",
    "        worksheet.add_table(0, 0, max_row, max_col - 1, {'columns': column_settings, 'style': 'Table Style Medium 6'})\n",
    "\n",
    "    print(f\"Archivo Excel para PowerBI generado: {nombre_archivo_excel}\")\n",
    "\n",
    "# Generar el Excel para PowerBI\n",
    "generar_excel_powerbi(df_kpis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
